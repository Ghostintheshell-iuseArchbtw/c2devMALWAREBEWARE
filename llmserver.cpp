// llama_server.cpp
#include <cpprest/json.h>
#include <cpprest/http_listener.h>
#include <llama.h>

using namespace web::http;
using namespace web::json;
using namespace std;

class LlamaServer {
public:
    LlamaServer() : listener_(uri("/")) {
        listener_.support_websocket(true);
        listener_.set_servlet([&]() {
            return make_shared<LlamaServlet>();
        });
    }

    void start() {
        listener_.open_async().wait();
    }

private:
    http_listener listener_;
    class LlamaServlet {
    public:
        LlamaServlet() {}

        void operator()(http_request request) {
            // Handle HTTP requests
            if (request.method() == methods::POST) {
                // Handle POST requests
                auto body = request.extract_string().get();
                auto input_text = body.begin()->second;
                auto output = llama::generate(input_text);
                auto response = web::http::status_codes::OK;
                auto headers = make_shared<web::http::header_collection>();
                headers->add(web::http::header_names::content_type, "application/json");
                auto body_json = output.to_json();
                request.reply(response, body_json, headers);
            } else {
                // Handle other methods
                auto response = web::http::status_codes::MethodNotAllowed;
                request.reply(response);
            }
        }
    };
};

int main() {
    LlamaServer server;
    server.start();
    return 0;
}
// llama_server.cpp
#include <cpprest/json.h>
#include <cpprest/http_listener.h>
#include <llama.h>

using namespace web::http;
using namespace web::json;
using namespace std;

class LlamaServer {
public:
    LlamaServer() : listener_(uri("/")) {
        listener_.support_websocket(true);
        listener_.set_servlet([&]() {
            return make_shared<LlamaServlet>();
        });
    }

    void start() {
        listener_.open_async().wait();
    }

private:
    http_listener listener_;
    class LlamaServlet {
    public:
        LlamaServlet() {}

        void operator()(http_request request) {
            // Handle HTTP requests
            if (request.method() == methods::POST) {
                // Handle POST requests
                auto body = request.extract_string().get();
                auto input_text = body.begin()->second;
                auto output = llama::generate(input_text);
                auto response = web::http::status_codes::OK;
                auto headers = make_shared<web::http::header_collection>();
                headers->add(web::http::header_names::content_type, "application/json");
                auto body_json = output.to_json();
                request.reply(response, body_json, headers);
            } else {
                // Handle other methods
                auto response = web::http::status_codes::MethodNotAllowed;
                request.reply(response);
            }
        }
    };
};

int main() {
    LlamaServer server;
    server.start();
    return 0;
}

